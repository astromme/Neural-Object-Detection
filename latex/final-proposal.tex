\documentclass{article}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{apacite}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subfigure}
%\usepackage{paralist}
%\usepackage{mdwlist}
\newcommand{\comment}[1]{}
\bibliographystyle{apacite}

\begin{document}
\title{Final Project Proposal}
\author{Andrew Stromme \& Ryan Carlson}
\date{April 6, 2010}
\maketitle

\section{Concrete Goal}

\section{Concept Goal}
We plan to use the Growing Neural Gas (GNG) algorithm to identify and categorize blobs of similarly colored/positioned pixels within an image. GNG is good at making categorizations and simplifications based on distance in the N-dimension feature space it is given. After the GNG has categorized the blobs present in the static image we would change the frame to a slightly different image where some of the objects have moved. This relates well to the real world example where robots see incremental frames where objects move slowly around the robot's field of view. Because GNGs are also good at adapting to changes in the input signal distribution we hope that the categorized blobs will be tracked by the GNG's nodes and edges.

\section{Implementation}
To implement this blob detection and tracking a small layer on top of GNG is needed. For a given frame this layer will extract vectors corresponding to position points on the image. For each point, the vector will tentatively consist of 5 dimensions, the x position, y position, r, g, and b values. The wrapper layer will pass into the GNG randomly selected input signals from the pool of these extracted vectors. This will allow the GNG to create and move nodes and edges to classify the similarities (in color or in physical distance) between input vectors. GNGs tend to create interconnected nodes that map similarities, but have no edge links between nodes that are far apart in the input space. Because of these edge links the resulting nodes and edges can be split up into 'blobs' that the GNG has detected. The wrapper will traverse the graphs that the GNG has created and give the higher level (AIBO) control the blobs that have been detected.

After a (large) number of time steps the blobs that have been detected by the GNG should settle down. Once this happens it is time to move to the next frame. We assume that each new frame will be very similar to the one that came before it because our intended environment is the real world with a fairly fast capture rate. For this new frame, the GNG will again be run on selected input signals as described above. However, the GNG will be a continuation of the nodes and edges created from the previous frame. This should in effect provide firstly a sort of bootstrapping for the GNG because all it has to do is shift the existing nodes over or shrink them slightly. Additionally, this will allow for the tracking of blobs across frames because most of the nodes and edges will stay the same. 

We think that there might be an issue with leaving 'old' structures behind if the content in the frames changes or moves too quickly. To compensate for this we plan to assign an age to each node as a record of what frame the network was in when that particular node or edge was last updated. This will allow the pruning of 'ghost' structures.

This implementation can translate to some form of object tracking and following on the AIBO robots. If the modified GNG described above uses the camera input from the AIBO's cameras then the robot can be given a higher level understanding of what objects are in its vision. From here, we can select a single object to track and then move the robot's head accordingly to try and keep it in the center of its vision.

\section{Stage/Steps}


\end{document}
