\documentclass{article}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{apacite}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subfigure}
%\usepackage{paralist}
%\usepackage{mdwlist}
\newcommand{\comment}[1]{}
\bibliographystyle{apacite}

\begin{document}
\title{Final Project Proposal}
\author{Andrew Stromme \& Ryan Carlson}
\date{April 6, 2010}
\maketitle

\section{Concrete Goal}

At a high level, our objective with this project is to implement a system that will allow an AIBO to identify and accurately track objects in its visual environment. We have seen that simple `blobify' filters allow the user to select a certain color and have the robot focus on the largest instance of that color. But in a real-life environment, objects are constantly moving around the plane of view. Moreover, they are moving closer and further away from the robot and may even change color if moved into different lighting conditions. Here blobify would clearly fail us by selected the new largest item of the specified color. We intend to implement a Growing Neural Gas (GNG) that is able to categorize objects by grouping regions of similar color and close proximity. We expect the GNG will enable an AIBO to track objects in a realistic environment.

\section{Concept Goal}

\section{Implementation}

\section{Stage/Steps}

We can break the process into two large sections: static object detection and dynamic object tracking. In the former, the focus will be on training the GNG to accurately categorize images. In the latter case, we will deal with moving images with objects that displace over time. We will work on static detection first. This will give us a strong sense of the capabilities of the GNG and how to use the categories to make the AIBO look at an object. After that part is working we can move onto moving images. The challenge here will be making sure the GNG accurately reflects the positions of the objects over time.

\subsection{Static Object Detection}

This stage can be broken down into three subtasks.

\begin{enumerate}
  \item Create a very simple, easy to categorize image using software like GIMP or Photoshop. The image will consist of a red box, a green box, and a blue box on a white background. The boxes will be well defined and will be pure in color. Since there will be no noise, we anticipate the GNG to classify this image without trouble.
  \item Use real-life images taken from the AIBO. We will have a range of environments from which pictures can be taken. One will be similar to the above, with the boxes drawn in marker on a white board. Another will be various objects placed around the robot lab, which will be a bit noisier and will have less contrast between foreground and background.
  \item Finally, we will use the categories generated by the GNG to make the AIBO attend in the direction of a specific object.
\end{enumerate}

\subsection{Dynamic Object Tracking}

This stage has three analogous subtasks as the object detection.

\begin{enumerate}
  \item Create a sequence computer-generated images where colored boxes incrementally move around a white background. Again, this input is noise free and will allow us to fine-tune the GNG for moving images.
  \item Use AIBO-provided videos of real-world environments. We will show objects like a bright green water bottle moving slowly across the scene or even another AIBO walking past.
  \item Lastly, we will again use the categories given by the GNG. Here, however, the categories will be changing and we hope to track these objects using the AIBO's head.
\end{enumerate}


\end{document}
